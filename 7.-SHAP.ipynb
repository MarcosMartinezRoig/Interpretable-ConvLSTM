{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', '..', 'ConvLSTM_PyTorch_master'))\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xarray as xr \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torchmetrics.image as t_metrics \n",
    "\n",
    "from data_standarization import mean_std_scaler\n",
    "\n",
    "from net_params_auto import convlstm_encoder_params, convlstm_decoder_params\n",
    "from encoder import Encoder\n",
    "from decoder import Decoder\n",
    "from model import ED\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "frames_predict = 12\n",
    "batch_size = 8\n",
    "num_layers = 4\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "print(device)\n",
    "\n",
    "split = 'train' #valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERA5_dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, split):\n",
    "        super(ERA5_dataset, self).__init__()\n",
    "\n",
    "        # Define the path\n",
    "        self.data_path = os.path.join(os.getcwd(), '..', '..', 'input_data', 'hourly')\n",
    "\n",
    "        # Read the data\n",
    "        if split == 'train':\n",
    "            print('Training dataset')\n",
    "            self.data = xr.open_dataset(os.path.join(self.data_path, 'train_data_hourly_m_s_2010_2019.nc'))['ws']\n",
    "        elif split == 'valid':\n",
    "            print('Validation dataset')\n",
    "            self.data = xr.open_dataset(os.path.join(self.data_path, 'valid_data_hourly_m_s_2020_2020.nc'))['ws']\n",
    "\n",
    "        #I order the coordinates\n",
    "        coords = self.data.coords\n",
    "        self.original_coords = {'time': coords['time'], 'latitude': coords['latitude'], 'longitude': coords['longitude']}\n",
    "        self.dims = [\"time\", \"latitude\", \"longitude\"]\n",
    "        \n",
    "        self.data = np.array(self.data)\n",
    "        self.data = torch.from_numpy(self.data).float()\n",
    "\n",
    "        self.dataset_spatial_size = self.data.shape[-1]\n",
    "\n",
    "        self.stats = xr.open_dataset(os.path.join(self.data_path, 'statistics_train_ds_per_pixel.nc'))\n",
    "        self.mean = self.stats[\"mean\"]\n",
    "        self.std = self.stats[\"std\"]\n",
    "\n",
    "        self.mean = np.array(self.mean)\n",
    "        self.mean = torch.from_numpy(self.mean).float()\n",
    "\n",
    "        self.std = np.array(self.std)\n",
    "        self.std = torch.from_numpy(self.std).float()\n",
    "        \n",
    "        self.data = mean_std_scaler(self.data, self.mean, self.std)\n",
    "        \n",
    "        #chunkify: That is, reshape data in an array where each element are a 3D cube of 12x144x144 \n",
    "        # I calcule data.shape[0]/12)*12 so that the number of selected data are divisible by 12\n",
    "        self.data = self.data[:int(self.data.shape[0]/frames_predict)*frames_predict].reshape((int(self.data.shape[0]/frames_predict), frames_predict, self.dataset_spatial_size, self.dataset_spatial_size))\n",
    "\n",
    "        # (inputs are given as data[:-1], targets as data[1:])\n",
    "        self.inputs = self.data[:-1]\n",
    "        self.targets = self.data[1:]\n",
    "\n",
    "        # I do the same transformations for the coordinats, specifically the time coordinate\n",
    "        self.orig_coords_time = np.array(self.original_coords[\"time\"])\n",
    "        self.orig_coords_lon = np.array(self.original_coords[\"longitude\"])\n",
    "        self.orig_coords_lat = np.array(self.original_coords[\"latitude\"])\n",
    "\n",
    "        self.orig_coords_time_reshaped = self.orig_coords_time[:int(self.orig_coords_time.shape[0] / frames_predict) * frames_predict].reshape((int(self.orig_coords_time.shape[0] / frames_predict), frames_predict))\n",
    "\n",
    "        self.input_coords_time_reshaped = self.orig_coords_time_reshaped[:-1]\n",
    "        self.target_coords_time_reshaped = self.orig_coords_time_reshaped[1:]\n",
    "\n",
    "        self.spatial_coords = {'latitude': coords['latitude'], 'longitude': coords['longitude']}\n",
    "\n",
    "        input_coords_time = self.input_coords_time_reshaped.reshape((int(self.input_coords_time_reshaped.shape[0] * frames_predict)))\n",
    "        target_coords_time = self.target_coords_time_reshaped.reshape((int(self.target_coords_time_reshaped.shape[0] * frames_predict)))\n",
    "\n",
    "        self.input_coords = {'time': input_coords_time, 'latitude': coords['latitude'], 'longitude': coords['longitude']}\n",
    "        self.target_coords = {'time': target_coords_time, 'latitude': coords['latitude'], 'longitude': coords['longitude']}\n",
    "\n",
    "        #print('input/target division done.')\n",
    "\n",
    "        self.dataset = TensorDataset(*(self.inputs, self.targets, self.targets))\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        input = self.dataset.tensors[0][index]\n",
    "        target = self.dataset.tensors[1][index]\n",
    "        sup = self.dataset.tensors[2][index]\n",
    "        \n",
    "        return input, target, sup, index\n",
    "    \n",
    "    #return dataset length\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset\n"
     ]
    }
   ],
   "source": [
    "data = ERA5_dataset(split=split)\n",
    "dataLoader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uplaod Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(os.getcwd(), '..', '..', 'experiments', 'convlstm_mae_4_PerPixel_mean-std_hourly_100_epochs_FP12', 'models', 'ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "\n",
    "    encoder_params = convlstm_encoder_params(num_layers, input_len=frames_predict, device=device)\n",
    "    decoder_params = convlstm_decoder_params(num_layers, output_len=frames_predict, device=device)\n",
    "\n",
    "    encoder = Encoder(encoder_params[0], encoder_params[1]).to(device)\n",
    "    decoder = Decoder(decoder_params[0], decoder_params[1], num_layers).to(device)\n",
    "    \n",
    "    net = ED(encoder, decoder)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)\n",
    "    \n",
    "    net.to(device)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Loading model\n",
    "    model_info = torch.load(os.path.join(model_path, 'checkpoint_50.pth.tar'), map_location=device)\n",
    "        \n",
    "    net.load_state_dict(model_info['state_dict'])\n",
    "\n",
    "    return net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29887/99982798.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_info = torch.load(os.path.join(model_path, 'checkpoint_50.pth.tar'), map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "print('ConvLSTM Model loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a forward model function compatible for SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward(input_tensor):\n",
    "    \"\"\"\n",
    "    Forward call to the model embebed in a function compatible with SHAP.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor (torch.Tensor): Input tensor [batch_size, 12, 1, 144, 144].\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Predicción of the model [batch_size, 12, 1, 144, 144].\n",
    "    \"\"\"\n",
    "\n",
    "    input_tensor = torch.tensor(input_tensor, dtype=torch.float32)\n",
    "\n",
    "    #model.eval()  \n",
    "    #with torch.no_grad():\n",
    "\n",
    "    output_frame = 0\n",
    "\n",
    "    if True:\n",
    "        input_tensor = input_tensor.to(device) \n",
    "        output = model(input_tensor).squeeze(2)\n",
    "        output = output[:, output_frame].sum()\n",
    "    return output#.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.model = model  # tu modelo pre-entrenado\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Modifica la salida del modelo para hacerla compatible con SHAP\n",
    "        (reducción a un valor escalar por cada imagen).\n",
    "        \n",
    "        Args:\n",
    "            input_tensor (torch.Tensor): Tensor de entrada [batch_size, 12, 1, 144, 144]\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Salida del modelo reducida a un escalar [batch_size].\n",
    "        \"\"\"\n",
    "        output = self.model(input_tensor).squeeze(2)  # [batch_size, 12, 144, 144]\n",
    "        output_frame = 0  # select one of the output frames\n",
    "        output = output[:, output_frame, :, :].mean()  # reduce using the mean/sum\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = WrappedModel(model).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrive all the data to create the background, that is, a representative subsample of the X_train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 913/913 [00:19<00:00, 46.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define empty lists to keep the predictions\n",
    "input_coll = torch.zeros((len(data), frames_predict, data.dataset_spatial_size, data.dataset_spatial_size), device='cpu')\n",
    "\n",
    "t = tqdm(dataLoader, leave=True, total=len(dataLoader))\n",
    "        \n",
    "for i, (inputVar, _, _, indices) in enumerate(t):\n",
    "\n",
    "    # save data according to the correct index\n",
    "    for j, index in enumerate(indices):\n",
    "                   \n",
    "        #saving variables\n",
    "        input_coll[index] = inputVar[j].detach().requires_grad_(True)\n",
    "\n",
    "del inputVar, indices\n",
    "\n",
    "# if KernelExplainer\n",
    "#input_coll = input_coll.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7303, 12, 144, 144])\n"
     ]
    }
   ],
   "source": [
    "print(input_coll.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a stratified subsable of the full dataset (4 blocks of 12 maps each one per month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset\n",
      "torch.Size([48, 12, 1, 144, 144])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Samples per season\n",
    "num_per_season = 12  # Total: 48 blocks of 12 maps each one (4 seasons; 3 months/station -> 4 blocks of 12 maps each one/month)\n",
    "\n",
    "# Split data per season\n",
    "if split == 'train':\n",
    "\n",
    "    print('Training dataset')\n",
    "\n",
    "    winter_idx = np.concatenate([np.arange(0, 182), np.arange(692, 731)])  # Winter (December-March, and November-December)\n",
    "    winter_idx = np.array([winter_idx + 731 * i for i in range(10)]).flatten()  # Winter for 10 years\n",
    "\n",
    "    spring_idx = np.array([np.arange(182, 362) + 731 * i for i in range(10)]).flatten()  # Spring (March-June)\n",
    "    summer_idx = np.array([np.arange(362, 542) + 731 * i for i in range(10)]).flatten()  # Summer (July-September)\n",
    "    autumn_idx = np.array([np.arange(542, 692) + 731 * i for i in range(10)]).flatten()  # Autumn (September-December)\n",
    "\n",
    "elif split == 'valid':\n",
    "    print('Validation dataset')\n",
    "\n",
    "    winter_idx = np.concatenate([np.arange(0, 182), np.arange(692, 731)])  # Winter (December-March)\n",
    "    spring_idx = np.arange(182, 362)  # Spring (March-June)\n",
    "    summer_idx = np.arange(362, 542)  # Summer (July-September)\n",
    "    autumn_idx = np.arange(542, 692)  # Autumn (September-December)\n",
    "\n",
    "\n",
    "# Random choice (sampling)\n",
    "winter_samples = resample(winter_idx, n_samples=num_per_season, random_state=42)\n",
    "spring_samples = resample(spring_idx, n_samples=num_per_season, random_state=42)\n",
    "summer_samples = resample(summer_idx, n_samples=num_per_season, random_state=42)\n",
    "autumn_samples = resample(autumn_idx, n_samples=num_per_season, random_state=42)\n",
    "\n",
    "# Join dataset\n",
    "selected_indices = np.concatenate([winter_samples, spring_samples, summer_samples, autumn_samples])\n",
    "background = input_coll[selected_indices] \n",
    "# if not KernelExplainer\n",
    "background = background.unsqueeze(2)\n",
    "# if KernelExplainer\n",
    "#background = np.expand_dims(background, axis=2)\n",
    "\n",
    "del winter_idx, spring_idx, summer_idx, autumn_idx, winter_samples, spring_samples, summer_samples, autumn_samples, selected_indices\n",
    "\n",
    "print(background.shape)\n",
    "print(type(background))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an exaplainer for SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some explainers (KernelExplainer, DeepExplainer) needs a fixed background. Others (GradientExplainer, Explainer) don't. Use (model) or (model, background) depending on that \n",
    "\n",
    "#expainer = shap.Explainer(model, background) # Works with all models. Automátically select the best method\n",
    "\n",
    "#explainer = shap.DeepExplainer(model=model, background=background) # Works well with TensorFlow/Keras but has some problems with PyTorch. Based on DeepLIFT, useful for NN.\n",
    "explainer = shap.GradientExplainer(model=wrapped_model, data=background, batch_size=1, local_smoothing=0) # Works well with TensorFlow/Keras/PyTorch. Based on Gradient SHAP. Work well with differenciable models\n",
    "#explainer = shap.KernelExplainer(model_forward, background) # Works well with any model. Based on SHAP kernel, similar to LIME, computationally cost.\n",
    "\n",
    "#shap.PartitionExplainer(model, X): # Divide the space of the input in regions and calcule SHAP values. Fast for complex models\n",
    "#shap.SamplingExplainer(model, X): Based in random sampling of coalitions, useful for fast estimations.\n",
    "\n",
    "#There are other model specific expliners like shap.TreeExplainer(model) or shap.LinearExplainer(model, x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain shap values for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_number = np.random.randint(0, input_coll.shape[0])\n",
    "\n",
    "test = input_coll[random_number].unsqueeze(0).unsqueeze(2)\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12, 1, 144, 144])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "output = model(background[:8])\n",
    "print(output.shape)\n",
    "print(output.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "output = wrapped_model(background[:8])\n",
    "print(output.shape)\n",
    "print(output.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 12, 1, 144, 144])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Marcos/lib/python3.9/site-packages/shap/explainers/_gradient.py:158\u001b[0m, in \u001b[0;36mGradientExplainer.shap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshap_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, nsamples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, ranked_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_rank_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, rseed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_variances\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the values for the model applied to X.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranked_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_rank_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_variances\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Marcos/lib/python3.9/site-packages/shap/explainers/_gradient.py:598\u001b[0m, in \u001b[0;36m_PyTorchGradient.shap_values\u001b[0;34m(self, X, nsamples, ranked_outputs, output_rank_order, rseed, return_variances)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, nsamples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[1;32m    597\u001b[0m     batch \u001b[38;5;241m=\u001b[39m [samples_input[c][b:\u001b[38;5;28mmin\u001b[39m(b\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,nsamples)]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))]\n\u001b[0;32m--> 598\u001b[0m     grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    599\u001b[0m grad \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mconcatenate([g[z] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads], \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata))]\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# assign the attributions to the right part of the output arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Marcos/lib/python3.9/site-packages/shap/explainers/_gradient.py:479\u001b[0m, in \u001b[0;36m_PyTorchGradient.gradient\u001b[0;34m(self, idx, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m X \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mrequires_grad_() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m    478\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39mX)\n\u001b[0;32m--> 479\u001b[0m selected \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     interim_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mtarget_input\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 0"
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(background[:1])#, ranked_outputs=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(preds, targets, spain_mask, frame):\n",
    "    \n",
    "    metric_dict = {}\n",
    "\n",
    "    metrics = ['l1Error', 'l2Error', 'Bias_time', 'Bias_space', 'Corr_time', 'Corr_space', 'RMSE_time', 'RMSE_space']#, 'StructuralSimilarityIndexMeasure', 'UniversalImageQualityIndex']\n",
    "\n",
    "    metric_settings = {\n",
    "        'l1Error': {},\n",
    "        'l2Error': {},\n",
    "        'Bias_time': {},\n",
    "        'Bias_space': {},\n",
    "        'Corr_time': {},\n",
    "        'Corr_space': {},\n",
    "        'RMSE_time': {},\n",
    "        'RMSE_space': {},\n",
    "        'StructuralSimilarityIndexMeasure': {'torchmetric_settings': {}},\n",
    "        'UniversalImageQualityIndex': {'torchmetric_settings': {}},\n",
    "        'FrechetInceptionDistance': {'torchmetric_settings': {}},\n",
    "        'KernelInceptionDistance': {'torchmetric_settings': {}}\n",
    "    }\n",
    "\n",
    "    for metric in metrics:\n",
    "\n",
    "        #print('Calculating {}...'.format(metric))\n",
    "\n",
    "        settings = metric_settings[metric]\n",
    "\n",
    "        spain_mask_bool = True\n",
    "\n",
    "        if 'l1Error' in metric:\n",
    "            \n",
    "            l1_loss_t, l1_loss_spain = compute_loss(preds, targets, nn.L1Loss(reduction='mean'), spain_mask, spain_mask_bool)\n",
    "\n",
    "            metric_dict[f'{frame}/l1Error_total'] = l1_loss_t\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/l1Error_spain'] = l1_loss_spain\n",
    "\n",
    "        elif 'l2Error' in metric:\n",
    "            \n",
    "            l2_loss_t, l2_loss_spain = compute_loss(preds, targets, nn.MSELoss(reduction='mean'), spain_mask, spain_mask_bool)\n",
    "            metric_dict[f'{frame}/l2Error_total'] = l2_loss_t\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/l2Error_spain'] = l2_loss_spain\n",
    "\n",
    "        elif 'Bias_time' in metric:\n",
    "            \n",
    "            bias_map_time, bias_map_time_spain, bias_time, bias_time_spain = compute_bias_time(preds, targets, spain_mask, spain_mask_bool)\n",
    "            metric_dict[f'{frame}/Bias_map_time'] = bias_map_time\n",
    "            metric_dict[f'{frame}/Bias_time'] = bias_time\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/Bias_map_time_spain'] = bias_map_time_spain\n",
    "                metric_dict[f'{frame}/Bias_time_spain'] = bias_time_spain\n",
    "\n",
    "        elif 'Bias_space' in metric:\n",
    "            \n",
    "            bias_map_space, bias_map_space_spain, bias_space, bias_space_spain = compute_bias_space(preds, targets, spain_mask, spain_mask_bool)\n",
    "\n",
    "            metric_dict[f'{frame}/Bias_map_space'] = bias_map_space\n",
    "            metric_dict[f'{frame}/Bias_space'] = bias_space\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/Bias_map_space_spain'] = bias_map_space_spain\n",
    "                metric_dict[f'{frame}/Bias_space_spain'] = bias_space_spain\n",
    "\n",
    "        elif 'Corr_time' in metric:\n",
    "            \n",
    "            correlation_map_time, correlation_map_time_spain, correlation_time, correlation_time_spain = compute_corr_time(preds, targets, spain_mask, spain_mask_bool)\n",
    "\n",
    "            metric_dict[f'{frame}/Corr_map_time'] = correlation_map_time\n",
    "            metric_dict[f'{frame}/Corr_time'] = correlation_time\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/Corr_map_time_spain'] = correlation_map_time_spain\n",
    "                metric_dict[f'{frame}/Corr_time_spain'] = correlation_time_spain\n",
    "\n",
    "        elif 'Corr_space' in metric:\n",
    "            \n",
    "            correlation_map_space, correlation_map_space_spain, correlation_space, correlation_space_spain = compute_corr_space(preds, targets, spain_mask, spain_mask_bool)\n",
    "\n",
    "            metric_dict[f'{frame}/Corr_map_space'] = correlation_map_space\n",
    "            metric_dict[f'{frame}/Corr_space'] = correlation_space\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/Corr_map_space_spain'] = correlation_map_space_spain\n",
    "                metric_dict[f'{frame}/Corr_space_spain'] = correlation_space_spain\n",
    "\n",
    "\n",
    "        elif 'RMSE_time' in metric:\n",
    "            \n",
    "            rmse_map_time, rmse_map_time_spain, rmse_time, rmse_time_spain = compute_rmse_time(preds, targets, spain_mask, spain_mask_bool)\n",
    "\n",
    "            metric_dict[f'{frame}/RMSE_map_time'] = rmse_map_time\n",
    "            metric_dict[f'{frame}/RMSE_time'] = rmse_time\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/RMSE_map_time_spain'] = rmse_map_time_spain\n",
    "                metric_dict[f'{frame}/RMSE_time_spain'] = rmse_time_spain\n",
    "\n",
    "        elif 'RMSE_space' in metric:\n",
    "            \n",
    "            rmse_map_space, rmse_map_space_spain, rmse_space, rmse_space_spain = compute_rmse_space(preds, targets, spain_mask, spain_mask_bool)\n",
    "\n",
    "            metric_dict[f'{frame}/RMSE_map_space'] = rmse_map_space\n",
    "            metric_dict[f'{frame}/RMSE_space'] = rmse_space\n",
    "            if spain_mask_bool:\n",
    "                metric_dict[f'{frame}/RMSE_map_space_spain'] = rmse_map_space_spain\n",
    "                metric_dict[f'{frame}/RMSE_space_spain'] = rmse_space_spain\n",
    "\n",
    "\n",
    "        else:\n",
    "            metric_outputs = calculate_metric(metric, preds, targets, torchmetrics_settings=settings['torchmetric_settings'])\n",
    "            metric_dict[f'{frame}/{metric}'] = metric_outputs\n",
    "\n",
    "            #if len(metric_outputs) > 1:\n",
    "            #    for k, metric_name in enumerate(settings['outputs']):\n",
    "            #        metric_dict[f'{frame}/{metric}_{metric_name}'] = metric_outputs[k]\n",
    "            #else:\n",
    "            #    metric_dict[f'{frame}/{metric}'] = metric_outputs[0]\n",
    "\n",
    "    return metric_dict\n",
    "\n",
    "def compute_loss(pred, target, loss_fn, spain_mask, spain_bool):\n",
    "\n",
    "    assert pred.shape == target.shape, \"The prediction and target dimensions are different\"\n",
    "\n",
    "    loss_total = loss_fn(pred, target).item()\n",
    "\n",
    "    if spain_bool:\n",
    "        # Create a mask to ignore NaN values\n",
    "        mask = ~torch.isnan(spain_mask.unsqueeze(0).expand_as(pred))\n",
    "\n",
    "        # Apply masks to vectors\n",
    "        pred_spain = pred[mask]\n",
    "        target_spain = target[mask]\n",
    "\n",
    "        loss_spain = loss_fn(pred_spain, target_spain).item()\n",
    "\n",
    "    return loss_total, loss_spain\n",
    "\n",
    "def compute_bias_time(pred, target, mask_spain, spain_bool):\n",
    "\n",
    "    assert pred.shape == target.shape, \"The prediction and target dimensions are different\"\n",
    "\n",
    "    bias_map_time = torch.mean(pred - target, dim=0)\n",
    "\n",
    "    # Máscara para España\n",
    "    if spain_bool:\n",
    "        bias_map_time_spain = torch.where(mask_spain.isnan(), float('nan'), bias_map_time)\n",
    "    else:\n",
    "        bias_map_time_spain = torch.zeros_like(bias_map_time)\n",
    "\n",
    "    return (bias_map_time, bias_map_time_spain, torch.nanmean(bias_map_time).item(), torch.nanmean(bias_map_time_spain).item())\n",
    "\n",
    "def compute_bias_space(pred, target, mask_spain, spain_bool):\n",
    "\n",
    "    assert pred.shape == target.shape, \"The prediction and target dimensions are different\"\n",
    "\n",
    "    # First, the spatial dimension (lat and lon) are planned. Dimensions now is time, lat * lon\n",
    "    pred_flattened = pred.view(pred.shape[0], -1)\n",
    "    target_flattened = target.view(pred.shape[0], -1)\n",
    "\n",
    "    # Calculation of the bias\n",
    "    bias_map_space = torch.mean(pred_flattened - target_flattened, dim=1)\n",
    "\n",
    "    # Spain_mask\n",
    "    if spain_bool:\n",
    "        mask = ~torch.isnan(mask_spain.flatten())\n",
    "        pred_spain = pred_flattened[:, mask]\n",
    "        target_spain = target_flattened[:, mask]  \n",
    "\n",
    "        bias_map_space_spain = torch.mean(pred_spain - target_spain, dim=1)\n",
    "                \n",
    "    return bias_map_space, bias_map_space_spain, torch.nanmean(bias_map_space).item(), torch.nanmean(bias_map_space_spain).item()\n",
    "  \n",
    "def compute_corr_time(pred, target, mask_spain, spain_bool):\n",
    "\n",
    "    assert pred.shape == target.shape, \"The prediction and target dimensions are different\"\n",
    "\n",
    "    # Calculation of the Correlation: \n",
    "    # r = Cov(X, Y)/(sigma_x * sigma_y)\n",
    "    \n",
    "    # Calcule the means\n",
    "    pred_mean  = torch.mean(pred, dim=0)\n",
    "    target_mean = torch.mean(target, dim=0)\n",
    "\n",
    "    # Calcule the Covariance and standard deviations\n",
    "    covariance = torch.mean(pred * target, dim=0) - pred_mean * target_mean\n",
    "    pred_var = torch.mean(pred ** 2, dim=0) - pred_mean ** 2\n",
    "    target_var = torch.mean(target ** 2, dim=0) - target_mean ** 2\n",
    "\n",
    "    # Correlation\n",
    "    corr_map_time = covariance / (torch.sqrt(pred_var) * torch.sqrt(target_var))\n",
    "\n",
    "    # Check for pixels with standard variance approximately 0, i.e., correlation values >1 or <-1\n",
    "    corr_map_time[corr_map_time>1] = float('nan')\n",
    "    corr_map_time[corr_map_time<-1] = float('nan')\n",
    "\n",
    "    # Spain_mask\n",
    "    if spain_bool:\n",
    "        corr_map_time_spain = torch.where(mask_spain.isnan(), float('nan'), corr_map_time)\n",
    "    else:\n",
    "        corr_map_time_spain = torch.zeros_like(corr_map_time)\n",
    "\n",
    "    return corr_map_time, corr_map_time_spain, torch.nanmean(corr_map_time).item(), torch.nanmean(corr_map_time_spain).item()\n",
    "\n",
    "def compute_corr_space(pred, target, mask_spain, spain_bool):\n",
    "\n",
    "    assert pred.shape == target.shape, \"The prediction and target dimensions are different\"\n",
    "\n",
    "    # First, the spatial dimension (lat and lon) are planned. Dimensions now is time, lat * lon\n",
    "    pred_flattened = pred.view(pred.shape[0], -1)\n",
    "    target_flattened = target.view(pred.shape[0], -1)\n",
    "\n",
    "    # Calculation of the Means\n",
    "    pred_mean = torch.mean(pred_flattened, dim=1)\n",
    "    target_mean = torch.mean(target_flattened, dim=1)\n",
    "\n",
    "    # Calculation of covariance and standard deviations\n",
    "    covariance = torch.mean(pred_flattened * target_flattened, dim=1) - pred_mean * target_mean\n",
    "    pred_var = torch.mean(pred_flattened ** 2, dim=1) - pred_mean ** 2\n",
    "    target_var = torch.mean(target_flattened ** 2, dim=1) - target_mean ** 2\n",
    "\n",
    "    # Correlation\n",
    "    corr_map_space = covariance / (torch.sqrt(pred_var) * torch.sqrt(target_var))\n",
    "    corr_map_space[torch.isnan(corr_map_space)] = 0\n",
    "\n",
    "    # Spain_mask\n",
    "    if spain_bool:\n",
    "        mask = ~torch.isnan(mask_spain.flatten())\n",
    "        pred_spain = pred_flattened[:, mask]\n",
    "        target_spain = target_flattened[:, mask]\n",
    "\n",
    "        # Calculation of the Means\n",
    "        pred_mean_spain = torch.mean(pred_spain, dim=1)\n",
    "        target_mean_spain = torch.mean(target_spain, dim=1)\n",
    "\n",
    "        # Calculation of covariance and standard deviations\n",
    "        covariance_spain = torch.mean(pred_spain * target_spain, dim=1) - pred_mean_spain * target_mean_spain\n",
    "        pred_var_spain = torch.mean(pred_spain ** 2, dim=1) - pred_mean_spain ** 2\n",
    "        target_var_spain = torch.mean(target_spain ** 2, dim=1) - target_mean_spain ** 2\n",
    "\n",
    "        # Correlation\n",
    "        corr_map_space_spain = covariance_spain / (torch.sqrt(pred_var_spain) * torch.sqrt(target_var_spain))\n",
    "        corr_map_space_spain[torch.isnan(corr_map_space_spain)] = 0    \n",
    "                \n",
    "    return corr_map_space, corr_map_space_spain, torch.nanmean(corr_map_space).item(), torch.nanmean(corr_map_space_spain).item()\n",
    "\n",
    "def compute_rmse_time(pred, target, mask_spain, spain_bool):\n",
    "\n",
    "    assert pred.shape == target.shape, \"The prediction and target dimensions are different\"\n",
    "\n",
    "    # Calculation of the Full RMSE\n",
    "    rmse_map_time = torch.sqrt(torch.mean((pred - target) ** 2, dim=0))\n",
    "\n",
    "    # Spain_mask\n",
    "    if spain_bool:\n",
    "        rmse_map_time_spain = torch.where(mask_spain.isnan(), float('nan'), rmse_map_time)\n",
    "    else:\n",
    "        rmse_map_time_spain = torch.zeros_like(rmse_map_time)\n",
    "\n",
    "    return rmse_map_time, rmse_map_time_spain, torch.nanmean(rmse_map_time).item(), torch.nanmean(rmse_map_time_spain).item() \n",
    "\n",
    "def compute_rmse_space(pred, target, mask_spain, spain_bool):\n",
    "\n",
    "    assert pred.shape == target.shape, \"The prediction and target dimensions are different\"\n",
    "\n",
    "    # First, the spatial dimension (lat and lon) are planned. Dimensions now is time, lat * lon\n",
    "    pred_flattened = pred.view(pred.shape[0], -1)\n",
    "    target_flattened = target.view(pred.shape[0], -1)\n",
    "\n",
    "    # Calculation of the RMSE\n",
    "    rmse_map_space = torch.sqrt(torch.mean((pred_flattened - target_flattened) ** 2, dim=1))\n",
    "\n",
    "    # Spain_mask\n",
    "    if spain_bool:\n",
    "        mask = ~torch.isnan(mask_spain.flatten())\n",
    "        pred_spain = pred_flattened[:, mask]\n",
    "        target_spain = target_flattened[:, mask]\n",
    "\n",
    "        rmse_map_space_spain = torch.sqrt(torch.mean((pred_spain - target_spain) ** 2, dim=1))\n",
    "                \n",
    "    return rmse_map_space, rmse_map_space_spain, torch.nanmean(rmse_map_space).item(), torch.nanmean(rmse_map_space_spain).item()\n",
    "\n",
    "def calculate_metric(name_expr, pred, target, torchmetrics_settings={}, part=5000):\n",
    "\n",
    "    metric_str = [m for m in t_metrics.__dict__.keys() if (name_expr == m)]\n",
    "\n",
    "    if len(metric_str) == 0:\n",
    "        metric_str = [m for m in t_metrics.__dict__.keys() if (name_expr in m)]\n",
    "        if len(metric_str) > 1:\n",
    "            warnings.warn('found multiple hits for metric name {}. Will use {}'.format(name_expr, metric_str[0]))\n",
    "\n",
    "    assert len(metric_str) > 0, 'metric {} not found in torchmetrics.image. Maybe torch-fidelity is missing.'.format(name_expr)\n",
    "\n",
    "    metric = t_metrics.__dict__[metric_str[0]](**torchmetrics_settings)\n",
    "\n",
    "    total_sum = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    for i in range(0, pred.size(0), part):\n",
    "\n",
    "        batch_preds = pred[i:min(i + part, pred.size(0))]\n",
    "        batch_targets = target[i:min(i + part, pred.size(0))]\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            value = metric(batch_preds.unsqueeze(1), batch_targets.unsqueeze(1)).item()\n",
    "            total_sum += value\n",
    "            total_batches += 1\n",
    "    \n",
    "    del batch_preds, batch_targets\n",
    "\n",
    "    return total_sum/total_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the spanish map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path\n",
    "data_path = os.path.join(os.getcwd(), '..', '..', 'input_data', 'hourly')\n",
    "\n",
    "# Read the data\n",
    "spain_mask = xr.open_dataset(os.path.join(data_path, 'mask_spain.nc'))[\"mask_spain\"].values\n",
    "spain_mask = torch.tensor(spain_mask).to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataLoader, data):\n",
    "\n",
    "    # Define empty lists to keep the predictions\n",
    "    target_coll = torch.zeros((len(data), frames_predict, data.dataset_spatial_size, data.dataset_spatial_size), device='cpu')\n",
    "    pred_coll = torch.zeros((len(data), frames_predict, data.dataset_spatial_size, data.dataset_spatial_size), device='cpu')\n",
    "\n",
    "    loss_aver_test = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        t = tqdm(dataLoader, leave=True, total=len(dataLoader))\n",
    "        \n",
    "        for i, (inputVar, targetVar, _, indices) in enumerate(t):\n",
    "\n",
    "            #t.set_description(\"Epoch = {}\".format(i))\n",
    "            \n",
    "            inputs = inputVar.to(device)\n",
    "            targets = targetVar.to(device) \n",
    "                          \n",
    "            # unsqueeze(2): Add the dimension of channel, needed for the model: from (B, 12, H, W) to (B, 12, 1, H, W). \n",
    "            # squeeze(): Remove an unnecessary dimension of channels (channel = 1): from (B, 12, 1, H, W) to (B, 12, H, W). \n",
    "            preds = model(inputs.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "            #loss = loss_functions.choose_loss(preds, targets, x, args)#.requires_grad_()\n",
    "            loss = torch.abs(preds - targets).mean() \n",
    "\n",
    "            loss_aver_test += loss.item() #/ preds.shape[0]\n",
    "\n",
    "            # save data according to the correct index\n",
    "            for j, index in enumerate(indices):\n",
    "                   \n",
    "                #saving variables\n",
    "                #input_coll[index] = inputs[j].detach().cpu()\n",
    "                target_coll[index] = targets[j].detach().cpu()\n",
    "                pred_coll[index] = preds[j].detach().cpu()\n",
    "\n",
    "            t.set_postfix({'TestLoss': '{:.6f}'.format(loss_aver_test)})\n",
    "            \n",
    "            del inputs, targets, preds, indices\n",
    "\n",
    "        loss_aver_test /= (i+1)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return target_coll, pred_coll, loss_aver_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ERA5_dataset()\n",
    "dataLoader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, pred, loss_run = test(model, dataLoader, data)\n",
    "\n",
    "print()\n",
    "print('Base model')\n",
    "print('Test Loss: {:.3f}'.format(loss_run))\n",
    "print()\n",
    "\n",
    "# Reshape data\n",
    "targets = target.reshape(target.shape[0] * target.shape[1], target.shape[2], target.shape[3])\n",
    "preds = pred.reshape(pred.shape[0] * pred.shape[1], pred.shape[2], pred.shape[3])\n",
    "\n",
    "# Unstandarize data\n",
    "targets = targets * data.std + data.mean\n",
    "preds = preds * data.std + data.mean\n",
    "\n",
    "# Calcule metrics\n",
    "metrics = get_metrics(preds, targets, spain_mask, 1)\n",
    "\n",
    "for key, val in metrics.items():\n",
    "    if \"map\" not in key:\n",
    "        print('{}: {:.3f}'.format(key, val))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "del target, targets, pred, preds, loss_run, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permuted data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, dataLoader\n",
    "\n",
    "frame = 0 # from -11 to 0\n",
    "data = ERA5_dataset(frame=frame)\n",
    "dataLoader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, pred, loss_run = test(model, dataLoader, data)\n",
    "\n",
    "print()\n",
    "print('Base model')\n",
    "print('Test Loss: {:.3f}'.format(loss_run))\n",
    "print()\n",
    "\n",
    "# Reshape data\n",
    "targets = target.reshape(target.shape[0] * target.shape[1], target.shape[2], target.shape[3])\n",
    "preds = pred.reshape(pred.shape[0] * pred.shape[1], pred.shape[2], pred.shape[3])\n",
    "\n",
    "# Unstandarize data\n",
    "targets = targets * data.std + data.mean\n",
    "preds = preds * data.std + data.mean\n",
    "\n",
    "# Calcule metrics\n",
    "metrics = get_metrics(preds, targets, spain_mask, 1)\n",
    "\n",
    "for key, val in metrics.items():\n",
    "    if \"map\" not in key:\n",
    "        print('{}: {:.3f}'.format(key, val))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "del target, targets, pred, preds, loss_run, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {}\n",
    "\n",
    "print('Run base model one...')\n",
    "\n",
    "# Upload the data\n",
    "data = ERA5_dataset()\n",
    "dataLoader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=20)\n",
    "\n",
    "# Obtain normal predictions\n",
    "target, pred, loss_run = test(model, dataLoader, data)\n",
    "\n",
    "#print()\n",
    "#print('Base model')\n",
    "#print('Test Loss: {:.3f}'.format(loss_run))\n",
    "print()\n",
    "\n",
    "# Reshape data\n",
    "targets = target.reshape(target.shape[0] * target.shape[1], target.shape[2], target.shape[3])\n",
    "preds = pred.reshape(pred.shape[0] * pred.shape[1], pred.shape[2], pred.shape[3])\n",
    "\n",
    "# Unstandarize data\n",
    "targets = targets * data.std + data.mean\n",
    "preds = preds * data.std + data.mean\n",
    "\n",
    "# Calcule metrics\n",
    "metrics = get_metrics(preds, targets, spain_mask, 1)\n",
    "\n",
    "all_metrics.update(metrics)\n",
    "\n",
    "#for key, val in metrics.items():\n",
    "    #if \"map\" not in key:\n",
    "        #print('{}: {:.3f}'.format(key, val))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "del data, dataLoader, target, pred, preds, loss_run, metrics\n",
    "\n",
    "print()\n",
    "\n",
    "print('Run with modified data using Permutance Feature')\n",
    "for frame in range(-11, 1, 1):\n",
    "    print('frame: ', frame)\n",
    "    print()\n",
    "\n",
    "    # Upload the data permuted\n",
    "    data = ERA5_dataset(frame=frame)\n",
    "    dataLoader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=False, num_workers=20)\n",
    "\n",
    "    # Obtain predictions with permuted data\n",
    "    _, pred, loss_run = test(model, dataLoader, data)\n",
    "\n",
    "    #print()\n",
    "    #print('Base model')\n",
    "    #print('Test Loss: {:.3f}'.format(loss_run))\n",
    "    print()\n",
    "\n",
    "    # Reshape data\n",
    "    preds = pred.reshape(pred.shape[0] * pred.shape[1], pred.shape[2], pred.shape[3])\n",
    "\n",
    "    # Unstandarize data\n",
    "    preds = preds * data.std + data.mean\n",
    "\n",
    "    # Calcule metrics\n",
    "    metrics = get_metrics(preds, targets, spain_mask, frame)\n",
    "\n",
    "    all_metrics.update(metrics)\n",
    "\n",
    "    #for key, val in metrics.items():\n",
    "        #if \"map\" not in key:\n",
    "            #print('{}: {:.3f}'.format(key, val))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    del data, dataLoader, pred, preds, loss_run, metrics\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric dict example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_metrics = {}\n",
    "\n",
    "# L1 and L2 Error (generados entre 0.1 y 1.0, ya son positivos)\n",
    "#for frame in range(-11, 2):\n",
    "    #all_metrics[f'{frame}/l1Error_total'] = np.random.uniform(0.1, 1.0)\n",
    "    #all_metrics[f'{frame}/l1Error_spain'] = np.random.uniform(0.1, 1.0)\n",
    "    #all_metrics[f'{frame}/l2Error_total'] = np.random.uniform(0.1, 1.0)\n",
    "    #all_metrics[f'{frame}/l2Error_spain'] = np.random.uniform(0.1, 1.0)\n",
    "\n",
    "# Bias (generados entre 0 y 0.4)\n",
    "#for frame in range(-11, 2):\n",
    "    #all_metrics[f'{frame}/Bias_time'] = np.random.uniform(0, 0.4)\n",
    "    #all_metrics[f'{frame}/Bias_time_spain'] = np.random.uniform(0, 0.4)\n",
    "    #all_metrics[f'{frame}/Bias_space'] = np.random.uniform(0, 0.4)\n",
    "    #all_metrics[f'{frame}/Bias_space_spain'] = np.random.uniform(0, 0.4)\n",
    "\n",
    "# Corr (generados entre 0 y 1)\n",
    "#for frame in range(-11, 2):\n",
    "    #all_metrics[f'{frame}/Corr_time'] = np.random.uniform(0, 1.0)\n",
    "    #all_metrics[f'{frame}/Corr_time_spain'] = np.random.uniform(0, 1.0)\n",
    "    #all_metrics[f'{frame}/Corr_space'] = np.random.uniform(0, 1.0)\n",
    "    #all_metrics[f'{frame}/Corr_space_spain'] = np.random.uniform(0, 1.0)\n",
    "\n",
    "# SSIM and UIQI (generados entre 0 y 1)\n",
    "#for frame in range(-11, 2):\n",
    "    #all_metrics[f'{frame}/SSIM'] = np.random.uniform(0, 1.0)\n",
    "    #all_metrics[f'{frame}/UIQI'] = np.random.uniform(0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diff of each case respect to the base model (frame = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_diff = {}\n",
    "\n",
    "# Obtain the reference values (values for the base model)\n",
    "frame_1_values = {key.split('/')[1]: value for key, value in all_metrics.items() if key.startswith('1/')}\n",
    "\n",
    "# Calcule differences respect to the base\n",
    "for frame in range(-11, 1):    \n",
    "    for metric in frame_1_values.keys():\n",
    "        key = f'{frame}/{metric}'\n",
    "        if key in all_metrics:\n",
    "            metrics_diff[key] = np.abs(all_metrics[key] - frame_1_values[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing General Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for key, value in metrics_diff.items():\n",
    "    frame, metric = key.split('/')\n",
    "    data.append([frame, metric, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(data, columns=['Frame', 'Metric', 'Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_filtered = metrics_df[~metrics_df['Metric'].str.contains('map')]\n",
    "metrics_df_maps = metrics_df[metrics_df['Metric'].str.contains('map')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(x=\"Metric\", y=\"Value\", data=metrics_df_filtered)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Boxplot de Métricas Sin \"map\"')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Value')\n",
    "#plt.ylim([0,1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = metrics_df_filtered['Metric'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_metrics = len(metrics_list)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_metrics, ncols=1, figsize=(10, 5 * num_metrics))\n",
    "\n",
    "# Si solo hay un gráfico, lo convertimos a una lista para iterar\n",
    "if num_metrics == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Dibujar un barplot para cada métrica\n",
    "for i, metric in enumerate(metrics_list):\n",
    "    ax = axes[i]\n",
    "    metric_data = metrics_df_filtered[metrics_df_filtered['Metric'] == metric]\n",
    "    \n",
    "    # Usamos los valores directos (no promediamos)\n",
    "    frame_values = metric_data['Frame']\n",
    "    metric_values = metric_data['Value']\n",
    "        \n",
    "    # Dibujar las barras\n",
    "    ax.bar(frame_values, metric_values, color='blue', edgecolor='black')\n",
    "    \n",
    "    #ax.set_ylim(bottom=0)\n",
    "    \n",
    "    ax.set_title(f'Diagrama de Barras de {metric}')\n",
    "    ax.set_xlabel('Frame')\n",
    "    ax.set_ylabel(f'{metric}')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xticks(frame_values)  # Aseguramos que los frames estén en el eje X\n",
    "    \n",
    "# Ajustar el diseño\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Map Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the map values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of interesting metrics\n",
    "time_metrics_of_interest = [\"Bias_map_time\", \"Corr_map_time\", \"RMSE_map_time\", \"Bias_map_time_spain\", \"Corr_map_time_spain\", \"RMSE_map_time_spain\"]\n",
    "space_metrics_of_interest = [\"Bias_map_space\", \"Corr_map_space\", \"RMSE_map_space\", \"Bias_map_space_spain\", \"Corr_map_space_spain\", \"RMSE_map_space_spain\"]\n",
    "\n",
    "frames = list(range(-11, 1)) \n",
    "\n",
    "# Create empty lists\n",
    "time_results = np.zeros((len(time_metrics_of_interest), len(frames), 144, 144))\n",
    "space_results = np.zeros((len(space_metrics_of_interest), len(frames), 8772))\n",
    "\n",
    "# time\n",
    "for i, metric in enumerate(time_metrics_of_interest):\n",
    "    for j, frame in enumerate(frames):\n",
    "        key = f\"{frame}/{metric}\"  \n",
    "        if key in metrics_diff: #all_metrics:\n",
    "            time_results[i, j, :] = metrics_diff[key] #all_metrics[key]  \n",
    "\n",
    "# space\n",
    "for i, metric in enumerate(space_metrics_of_interest):\n",
    "    for j, frame in enumerate(frames):\n",
    "        key = f\"{frame}/{metric}\"  \n",
    "        if key in metrics_diff: #all_metrics:\n",
    "            space_results[i, j, :] = metrics_diff[key] #all_metrics[key]  \n",
    "\n",
    "# Call data class again to retrive coords.\n",
    "data = ERA5_dataset()\n",
    "\n",
    "# Convert to xarray \n",
    "time_ds = xr.Dataset({metric: ([\"frame\", \"latitude\", \"longitude\"], time_results[i]) for i, metric in enumerate(time_metrics_of_interest)},\n",
    "    coords={\"frame\": frames, \"latitude\": data.input_coords['latitude'], \"longitude\": data.input_coords['longitude']},\n",
    ")\n",
    "\n",
    "# Crear el dataset para 'space'\n",
    "space_ds = xr.Dataset({metric: ([\"frame\", \"time\"], space_results[i]) for i, metric in enumerate(space_metrics_of_interest)},\n",
    "    coords={\"frame\": frames,\"time\": data.input_coords['time']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_metric(dataset, metric):\n",
    "    \"\"\"\n",
    "    Plot of the 12 frames given a xarray.Dataset with dimensions (frame, lat, lon).\n",
    "    \n",
    "    Parameters:\n",
    "        dataset (xr.Dataset): Dataset with metrics.\n",
    "        metric (str): name of the metric.\n",
    "    \"\"\"\n",
    "    if metric not in dataset:\n",
    "        raise ValueError(f\"The metric '{metric}' is not in the dataset.\")\n",
    "\n",
    "    cmap = \"viridis\"\n",
    "    extent = [-10.3, 5, 31, 46.4]  \n",
    "    \n",
    "    frames = dataset[\"frame\"].values  \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    #vmin, vmax = dataset[metric].min().item(), dataset[metric].max().item()  \n",
    "\n",
    "    for i, frame in enumerate(frames):            \n",
    "        ax = axes[i]\n",
    "        ax.set_extent(extent)\n",
    "        gls = ax.gridlines(alpha=0.5, draw_labels=True, dms=True)\n",
    "        gls.right_labels = False\n",
    "        gls.top_labels = False\n",
    "        ax.coastlines(resolution='10m')\n",
    "        \n",
    "        data = dataset[metric].sel(frame=frame)\n",
    "\n",
    "        vmin, vmax = data.min().item(), data.max().item()  \n",
    "\n",
    "        im = ax.pcolormesh(dataset[\"longitude\"], dataset[\"latitude\"], data.values, cmap=cmap, vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
    "        cbar = plt.colorbar(im,ax=ax,fraction=0.046, pad=0.04)\n",
    "        cbar.set_label(label=f'{metric}',size=14, labelpad=10)\n",
    "        ax.set_title(f'Frame: {frame}')\n",
    "\n",
    "    # Ajustar diseño\n",
    "    fig.suptitle(f\"Métrica: {metric}\", fontsize=16)\n",
    "    plt.subplots_adjust(right=0.9, top=0.95)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_metric(time_ds, \"Corr_map_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "def plot_space_metric(dataset, metric):\n",
    "    \"\"\"\n",
    "    Plot the 12 frames of a given metric from a spatial xarray.Dataset in 12 subplots.\n",
    "    \n",
    "    Parameters:\n",
    "        dataset (xr.Dataset): Dataset with metrics (dimensions: frame, time).\n",
    "        metric (str): Name of the metric to plot.\n",
    "    \"\"\"\n",
    "    if metric not in dataset:\n",
    "        raise ValueError(f\"The metric '{metric}' is not in the dataset.\")\n",
    "\n",
    "    frames = dataset[\"frame\"].values  \n",
    "    time_values = dataset[\"time\"].values  \n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(16, 10), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        ax = axes[i]\n",
    "        data = dataset[metric].sel(frame=frame)\n",
    "        \n",
    "        ax.plot(time_values, data, label=f'Frame {frame}')\n",
    "        ax.set_title(f'Frame {frame}')\n",
    "        ax.grid(True)\n",
    "\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "\n",
    "    fig.suptitle(f\"Metric vs time: {metric}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_space_metric(space_ds, \"Corr_map_space\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Marcos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
